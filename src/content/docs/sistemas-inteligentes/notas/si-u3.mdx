---
title: Unidad 3 - Agentes inteligentes
description: Que es un agente inteligente
---
import { Card } from '@astrojs/starlight/components';
import { CardGrid } from '@astrojs/starlight/components';

## ü§ñüß† Agentes inteligentes 

### üìñ Definici√≥n

<Card title="Agente Inteligente - Definici√≥n" icon='open-book'>
	Es cualquier cosa capaz de percibir su medioambiente con la ayuda de sensores y actuar en ese medio utilizando actuadores.
</Card>

![Agente Inteligente](assets/Agentes%20Inteligentes/Agente%20Inteligente.png)


### Percepci√≥n
Indica que el agente puede recibir entradas en cualquier instante. ==La secuencia de percepciones== de un agente refleja el historial completo de lo que el agente ha recibido.

Un agente tomar√° una decisi√≥n en un momento dado dependiendo de la secuencia completa de percepciones hasta ese instante.

En t√©rminos matem√°ticos se puede decir que el comportamiento del agente viene dado por la funci√≥n del agente que proyecta una percepci√≥n dada de una acci√≥n



Percepciones funci√≥n del agente ‚Üí Acciones
<br/>

>#### Ejemplo

| Secuencia de percepciones | Acci√≥n          |
| ------------------------- | --------------- |
| A, limpio                 | Mover derecha   |
| A, sucio                  | Aspirar         |
| B, limpio                 | mover izquierda |
| B, sucio                  | aspirar         |

----
## Agentes racionales 
<Card title="Agente racional - Definici√≥n" icon='open-book'>
	Un agente racional es aquel que hace lo correcto; es decir, cada elemento de la tabla que define la funci√≥n del agente se tendr√≠a que rellenar correctamente.
</Card>

<Card title="Agente racional - GPT" icon='information'>
	Un agente racional es un concepto utilizado en la inteligencia artificial y la teor√≠a de la decisi√≥n para describir un sistema que toma decisiones de manera √≥ptima bas√°ndose en la informaci√≥n disponible y sus objetivos. Un agente racional es capaz de percibir su entorno, razonar sobre la informaci√≥n disponible y elegir la acci√≥n m√°s adecuada para alcanzar sus objetivos.
</Card>

<Card title="¬øQu√© es hacer lo correcto?" icon='approve-check'>
	Como primera aproximaci√≥n, se puede decir que lo correcto es aquello que permite al agente obtener un mejor resultado.
</Card>


La racionalidad depende de cuatro factores:
1. La medida de rendimiento que define el criterio de √©xito.
2. El conocimiento acumulado del medio en el que habita el agente.
3. Las acciones que el agente puede llevar a cabo.
4. La secuencia de percepciones del agente hasta ese momento.

### Agente racional
En cada posible secuencia de percepciones, un agente racional deber√° emprender aquella acci√≥n que supuestamente maximice su medida de rendimiento, bas√°ndose en las evidencias aportadas por la secuencia de percepciones y en el conocimiento que el agente mantiene almacenado.

### Agente omnisciente
Es aquel que conoce el resultado de su acci√≥n y act√∫a de acuerdo con el; sin embargo en realidad la omnisciencia no es posible.

### Aprendizaje
Como no se conoce a priori todo el entorno, se debe percibir y aprender para poder maximizar el rendimiento (memoria).

### Exploraci√≥n
Recopilaci√≥n de informaci√≥n, realizando acciones con la intenci√≥n de modificar percepciones futuras y memorizando el resultado de cada acci√≥n.

### Autonom√≠a
Un agente racional debe poder aprender como tiene que compensar la falta de conocimiento que posee. Si no posee ning√∫n conocimiento inicial, debe actuar de forma aleatoria.

>A un agente racional hay que dotarlo de un conocimiento inicial y las capacidades de explorar y aprender

### Entorno de trabajo
B√°sicamente es el problema del mundo real que tiene que resolver el agente. Este incluye las medidas de rendimiento, el entorno, los actuadores y los sensores; estos son denominados REAS

(Rendimiento, Entorno, Actuadores, Sensores)

En el dise√±o de un agente racional el primer paso siempre consiste en especificar el entorno de trabajo de la forma m√°s completa posible.
<br/>

>#### Ejemplo - Agentes inteligentes

| Agente             | Medidas de rendimiento                                                                                                                                       | Entorno                                                                                                                                        | Actuadores                                                                                                                                                   | Sensores                                                                                                                                                                                 |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Garrotero          | N√∫mero de mesas limpias<br/><br/>Conteo de suministros<br/><br/>√çndice de satisfacci√≥n  como encuestas<br/><br/>N√∫mero de platos rotos<br/><br/>N√∫mero de accidentes | Distribuci√≥n del local<br/><br/>Materiales o superficie<br/><br/>Exterior o interior                                                               | Mecanismos de movimiento<br/><br/>Pinzas<br/><br/>Insumos para limpieza                                                                                          | Sensores de distancia<br/><br/>Sensores de humedad o l√≠quidos<br/><br/>Sensor infrarrojo<br/><br/>Sensor de bater√≠a<br/><br/>Sensores de temperatura<br/><br/>Dinam√≥metro<br/><br/>Sensor de presi√≥n |
| Diagn√≥stico m√©dico | Precisi√≥n y rapidez en el diagn√≥stico.<br/><br/>N√∫mero de errores m√©dicos<br/><br/>Satisfacci√≥n del paciente<br/><br/>Eficiencia en el uso de recursos m√©dicos     | Ubicaci√≥n<br/><br/>Espacio suficiente<br/><br/>Conectividad<br/><br/>Suministro El√©ctrico<br/><br/>Posicionamiento de equipos<br/><br/>Acceso Controlado | Interfaces de usuario<br/><br/>Mecanismos para interactuar con el paciente<br/><br/>Sistema de comunicaci√≥n para compartir los resultados<br/><br/>Insumos m√©dicos | Dispositivos de entrada<br/><br/>Sensores biom√©tricos<br/><br/>Sensor de bater√≠a<br/><br/>Sensores de temperatura y humedad                                                                    |

----
## Propiedades entornos de trabajo
### Totalmente observable
Se da cuando los sensores del agente saben que basa en todo momento en su mundo (variables relevantes para la toma de decisiones)

### Parcialmente observables
Se refiere a un tipo de entorno en el que el agente no tiene acceso a toda la informaci√≥n relevante en cada momento. M√°s espec√≠ficamente, el agente solo puede percibir una porci√≥n limitada o censurada del estado total del entorno.

### Determinista
Es cuando el siguiente estado del sistema esta determinado por el estado actual y la  acci√≥n que tome el agente.

### Estoc√°stico
Es aquel en el que las acciones del agente inteligente no conducen a resultados deterministas y predecibles con total certeza. En su lugar, el resultado de cada acci√≥n est√° sujeto a cierto grado de incertidumbre o aleatoriedad.

### Epis√≥dico
Cuando el agente act√∫a en episodios at√≥micos, es decir para cada percepci√≥n existe
solo una acci√≥n a realizar. Los episodios determinan el comportamiento del agente.

### Secuencial
Las decisiones actuales pueden afectar las decisiones futuras, es decir si se toma en cuenta el historial de estados del medio y acciones del agente.

### Est√°tico
El entorno es el mismo si el agente est√° presente o no, es decir no es susceptible a cambios.

### Din√°mico
Cuando el entorno cambia con el paso de tiempo, incluso es diferente con/sin el agente.

### Discreto
Tiene un n√∫mero de estados finito y bien definido de estados.

### Continuo
El n√∫mero de estados y acciones es continuo, se decir el estado del sistema no es el mismo en este momento que 0.0000001 segundos despu√©s.

### Agente individual y multiagente
#### Entorno individual
En este tipo de entorno, solo interact√∫a un agente inteligente. El agente percibe el estado del entorno, selecciona y ejecuta una acci√≥n, y recibe una recompensa o retroalimentaci√≥n en funci√≥n de los resultados de esa acci√≥n. El objetivo del agente en un entorno individual es aprender una pol√≠tica √≥ptima que maximice su recompensa total a lo largo del tiempo.

#### Multiagente
En este tipo de entorno, interact√∫an m√∫ltiples agentes inteligentes, cada uno con su propio objetivo y pol√≠tica de acci√≥n. Los agentes pueden colaborar entre s√≠ para lograr un objetivo com√∫n o competir por recursos limitados. La complejidad de un entorno multiagente aumenta en comparaci√≥n con un entorno individual, ya que los agentes deben tener en cuenta las acciones y reacciones de los dem√°s agentes al tomar decisiones.

### Agentes competitivos y cooperativos
#### Entornos con agentes competitivos
En estos entornos, los agentes compiten entre s√≠ por recursos limitados o intentan maximizar sus propias recompensas a expensas de las dem√°s. Cada agente tiene su propia pol√≠tica y objetivo, y las acciones de un agente pueden afectar directamente las recompensas de los dem√°s.

#### Entornos con agentes cooperativos
En estos entornos, los agentes trabajan juntos para lograr un objetivo com√∫n o maximizar una recompensa compartida. Los agentes deben colaborar y coordinar sus acciones para tener √©xito. 

----

## Estructura de un agente

``` java
Agente = arquitectura + programa
```

### Programas de agente
1. Recibir como entrada las lecturas de los sensores.
2. Procesar estas lecturas y determinar una acci√≥n.
3. Enviar la acci√≥n a realizar a los actuadores.

Tipos b√°sicos de programas de agente:
1. Agentes reactivos simples.
2. Agentes reactivos basados en modelos.
3. Agentes Basados en objetivos.
4. Agentes basados en utilidad.

----
## Agentes reactivos simples
Seleccionan sus acciones con base a las percepciones actuales, y no toman en cuenta la secuencia de percepciones pasadas.
- Reglas condici√≥n-acci√≥n
	- Si ¬´condici√≥n¬ª, entonces ¬´acci√≥n¬ª

>### Ejemplo - Robot aspiradora

![Agemte Aspirador](assets/Agentes%20Inteligentes/agenteRobotAs√¨radora.png)

```java
funcion aspiradora(ubicaci√≥n,estado) devuelve acci√≥n
	si estad = "Sucio" entonces devolver "Aspirar"
	sino
		si ubicaci√≥n = "A" entonces devolver "Derecha"
		sino
			si ubicaci√≥n = "B" entonces devolver "Izquierda"
```

![Agente Reactivo Simple](assets/Agentes%20Inteligentes/agenteReactivoSimple.png)

```java
funcion Agente_Reactivo_Simple(percepci√≥n) devuelve acci√≥n
	reglas : conjunto de reglas condici√≥n-acci√≥n

	estado ‚Üê Interpretar(percepci√≥n).
	regla ‚Üê Regla-conicidencia(estado, reglas).
	acci√≥n ‚Üê reglas[regla].
	devolver acci√≥n.
```

----
## Agentes reactivos basados en modelos

Esos agentes almacenan un estado interno que depende de la historia de percepciones
La actualizaci√≥n del estado interno depende de dos factores:
- Informaci√≥n de c√≥mo evoluciona el mundo independientemente del agente.
- Informaci√≥n de c√≥mo afectan al mundo las acciones del agente

>A estos lo denominamos **modelo del mundo**

![Agente Reactivo Basado en Modelos](assets/Agentes%20Inteligentes/agenteReactivoBasadoModelos.png)

```java
funcion Agente_Reactivo_Modelos(percepci√≥n) devuelve acci√≥n
	estado: descripci√≥n actual del estado del mundo.
	reglas: conjunto de reglas condici√≥n-acci√≥n.
	acci√≥n: la acci√≥n m√°s reciente.
	
	estado ‚Üê Actualizar-Estado(estado, acci√≥n, percepci√≥n).
	regla ‚Üê Regla-conicidencia(estado, reglas).
	acci√≥n ‚Üê Regla-Acci√≥n[regla].
	devolver acci√≥n.
```

---
## Agentes basados en objetivos

El conocimiento del mundo actual no es suficiente para decidir una acci√≥n.

Adem√°s de la descripci√≥n del estado actual, el agente necesita alg√∫n tipo de informaci√≥n sobre su meta que describa las situaciones que son deseables.

Se puede utilizar la informaci√≥n sobre los resultados de las acciones posibles para elegir las acciones que permitan alcanzar el objetivo.

El agente tiene que considerar secuencias complejas para encontrar el camino que le permita alcanzar el objetivo. La b√∫squeda y la planificaci√≥n son los sub-campos de la IA centrados en encontrar secuencias de acciones que permitan a los agentes alcanzar sus metas.

![Agente Basado en Objetivos](assets/Agentes%20Inteligentes/agenteBasadoObjetivos.png)

----
## Agentes basados en utilidad

En muchas ocasiones las metas no son suficientes para tener un comportamiento eficiente.
Podemos tener diferentes secuencias de acciones y obtener la misma meta.

Necesitamos una medida de eficiencia, es decir que acci√≥n es la m√°s √∫til.

Una funci√≥n de utilidad cuantifica un estado o una secuencia de estados.
Una funci√≥n de utilidad permite tomar decisiones en casos en las que las metas sean inadecuadas:
 - Metas conflictivas
 - Es posible que la meta no se pueda alcanzar

![Agente Basado en Utilidad](assets/Agentes%20Inteligentes/agenteBasadoUtilidad.png)

----
## Agentes que aprenden

Un agente que aprende tiene 4 componentes:
#### 1. Elemento de cr√≠tica
Es el responsable de realimentar la actuaci√≥n al agente al elemento de aprendizaje
#### 2. Elemento de aprendizaje
Responsable de las mejoras
#### 3. Elemento de actuaci√≥n
Responsable de seleccionar las acciones
#### 4. Generador de problemas
Sugiere acciones para alcanzar estados nuevos

